# note#8

[2023.11.14 - 9장 비지도학습 수업]

**Q1. K-평균 군집화에서 군집의 개수 k를 어떻게 결정하는 것이 좋은가요?**

A1. 

K-평균 군집화에서 군집의 개수 k는 중요한 하이퍼파라미터입니다.
이를 결정하기 위해 '엘보우 방법'이라고 하는 샘플과 그 샘플의 가장 가까운 군집 중심까지의 거리의 제곱의 합의 그래프로 그려보고 관성이 더 이상 크게 감소하지 않는 지점을 찾을 수 있습니다.
또한 실루엣 점수나 실루엣 다이어그램을 사용해 군집화의 품질을 평가할 수도 있습니다.

**Q1. 엘보우 방법과 실루엣 분석을 비교하여 설명해주세요.**

A1. 엘보우 방법은 군집 내 분산에 중점을 두는 반면, 실루엣 분석은 군집 간 구분과 내부 응집도를 모두 고려합니다. 정확도의 측면에서는 실루엣 분석은 군집의 질을 더욱 정확하게 평가하지만, 엘보우 방법은 빠르고 간단하지만 정확도에서는 약간 떨어질 수 있습니다. 

---

**Q2. 비지도 학습을 이용한 이상치 탐지에서 가우시안 혼합 모델을 사용하는 이점은 무엇인가요?**

A2. 

가우시안 혼합 모델은 데이터가 여러 개의 가우시안 분포로 구성되어 있다고 가정합니다.
이를 통해서 데이터의 복잡한 구조를 더 잘 이해하고, 이상치가 낮은 확률 밀도를 가지는 지역에 위치하는지를 판단할 수 있습니다.

**Q2. 가우시안 혼합 모델을 사용한 이상치 탐색에서 고려해야 할 사항은 무엇인가요?**

A2. 

가우시안 혼합 모델의 성능은 분포의 수에 크게 영향을 받습니다. 적은 수의 분포는 데이터의 복잡성을 포착하지 못할 수 있고, 너무 많은 수의 분포는 과적합을 발생시킬 수 있습니다. 이것을 감안하여 최적의 분포 수를 결정해야 합니다.

---

**Q3. DBSCAN에서 사용되는 'eps'와 'min_samples' 하이퍼파라미터는 어떻게 군집화에 영향을 미치나요?**

A3.

'eps'는 군집의 밀도를 결정하는 반경을 의미하고, 'min_samples'는 군집을 형성하는 데 필요한 최소 샘플 수를 의미합니다.
이 두 파라미터는 군집의 크기와 밀도를 조절하여 다양한 형태의 데이터에 적용될 수 있습니다.

**Q3. DBSCAN에서 사용되는 'eps'와 'min_samples' 하이퍼파라미터의 적절한 값은 어떻게 선택하나요?**

A3.

너무 작은 eps값은 과도한 군집을 생성할 수 있고, 너무 큰 eps값은 서로 다른 군집들이 합쳐지게 만들 수 있습니다. 데이터의 분포와 밀도에 따라 적절한 값을 조절하는 것이 중요합니다. 

너무 낮은 min_samples값은 작고 분산된 군집을 형성하고, 너무 높은 값은 크고 밀집된 군집을 형성합니다. 역시 데이터의 밀도를 고려하여 적절한 값을 선택하는것이 좋을것 같습니다.

---

**Q4. K-평균과 가우시안 혼합 모델에서 클러스터 개수를 결정하는 데 있어 실루엣 점수와 BIC/AIC 지표의 효율성은 어떻게 다른가요?**

A4. 

실루엣 점수는 클러스터 내부의 응집도와 클러스터 간 분리도를 기반으로 합니다.
BIC/AIC는 모델의 복잡성과 데이터에 대한 적합도를 동시에 고려합니다.
실루엣 점수는 클러스터의 질을 직관적으로 평가하는 반면, BIC/AIC는 모델 선택에 더 중점을 둡니다.

---

**Q5. 가우시안 혼합 모델은 어떤 유형의 데이터셋에서 잘 작동하지 않나요?**

A5. 

가우시안 혼합 모델은 타원형 클러스터를 가정하기 때문에,
비선형적인 형태나 복잡한 구조를 가진 데이터셋에서는 잘 작동하지 않을 수 있습니다.

**Q5. 그렇다면 비선형적인 형태나 복잡한 구조를 가진 데이터셋에서는 어떠한 방법이 효과적일까요?**

A5. 

DBSCAN과 스펙트럼 군집화 등의 방법을 사용하면 좋습니다. DBSCAN은 데이터의 밀집된 영역을 클러스터로 식별하고, 노이즈 포인트를 효과적으로 처리할 수 있기 때문에 비선형적인 테이더 구조에서도 효과적으로 사용할 수 있습니다. 

스펙트럼 군집화의 경우 데이터의 유사성 행렬을 기반으로 하여 고차원 데이터에서 비선형 구조를 포착하는데에 유용합니다. 이는 데이터 간의 관계를 그래프로 모델링하여 복잡한 구조에서 의미 있는 군집을 형성할 수 있도록 합니다.

---

**Q6. 군집을 사용한 준지도 학습 방법이 효과적인 경우는 어떤 상황인가요?**

A6. 

레이블이 없거나 부족한 데이터셋에서 군집을 사용하여 대표 샘플을 선정하고, 이를 통해 분류기를 훈련시킬 수 있습니다.
이 방법은 레이블이 매우 제한된 상황에서 효과적입니다.

**Q6. 군집을 사용한 준지도 학습 방법에서 어떤 알고리즘이나 모델을 사용하는 것이 좋을까요?**

A6. 

레이블이 없는 데이터에서 그룹을 식별하는데 k-평균 군집화를 사용할 수 있습니다. 데이터를 K개의 클러스터로 나누는 비지도 학습 알고리즘으로 이 방법은 각 클러스터의 중심점을 기반으로 데이터 포인트를 군집화하고, 클러스터의 중심점은 해당 클러스터 데이터 포인트들의 평균 위치를 가집니다. 이 알고리즘은 중심점과 데이터 포인트 간의 거리를 최소화하도록 반복하여 중심점을 조정합니다.

---

**Q7. 베이즈 가우시안 혼합 모델과 일반 가우시안 혼합 모델의 주요 차이점은 무엇인가요?**

A7. 

베이즈 가우시안 혼합 모델은 일반 가우시안 혼합 모델에 베이지안 접근 방식을 적용한 것입니다.
모델이 자동으로 군집의 수를 결정할 수 있도록 도와주며, 군집의 수에 대한 사전 지식을 활용하여 더 유연한 모델링이 가능합니다.
또한, 불필요한 군집을 자동으로 제거하는 기능도 포함합니다.

**Q7. 군집의 수를 자동으로 결정하는 것은 어떻게 작동하나요?**

A7. 

사전분포와 베이즈추론을 통해 군집의 수를 자동으로 결정합니다. 군집의 수에 대한 사전 지식을 확률 분포의 형태로 모델에 포함하고, 데이터와 사전 분포를 결합하여 군집의 수와 각 군집에 속하는 데이터 포인트의 확률을 추정합니다. 데이터가 주어질 때, 가능한 군집 수에 대해 추론하고 이들 중 데이터에 가장 잘 맞는 군집 수를 선택하는 방식으로 작동합니다.

---

**Q8. K-평균을 데이터 전처리 단계에서 사용하는 장점은 무엇인가요?**

A8. 

K-평균을 전처리 단계에서 사용하면 데이터의 차원을 줄이고,
유사한 데이터를 그룹화하여 머신러닝 모델의 학습 효율성을 높일 수 있습니다.

---

**Q9. 전체 데이터셋 대신 미니배치를 사용하는 K-평균의 장점과 단점은 무엇인가요?**

A9. 

미니배치 K-평균은 계산 속도가 빠르고 대용량 데이터셋에 적합합니다.
하지만 전체 데이터셋을 사용하는 일반 K-평균에 비해 이너셔가 약간 더 나쁠 수 있습니다.

**Q9. 이너셔는 무엇인가요?**

이너셔는 K-평균 군집화에서 각 데이터 포인트와 해당 군집 중심점 간의 거리 제곱의 총합으로 정의되며, 군집 내 응집도를 측정하는 지표입니다. 값이 낮을수록 군집 내 데이터 포인트들이 중심점에 밀접해 있음을 나타내며, 군집화의 효과성을 평가하는 중요한 지표입니다. 

그러나 이너셔는 군집의 수 K가 증가할수록 감소하는 경향이 있기 때문에 적절한 군집 수를 결정하기 위해서는 엘보우 방법 등 다른 방법과 함께 사용하는 것이 좋습니다.

---

**Q10. 실생활에서 군집 알고리즘이 어떻게 활용될 수 있는가요?**

A10. 

군집 알고리즘은 고객 세분화, 추천 시스템, 사회 네트워크 분석, 이미지 분할, 생물 정보학 등등의 다양한 분야에서 데이터의 구조를 이해하고 그룹화하는 데 활용될 수 있습니다.

---

**Q11. 서로 다른 군집 알고리즘을 선택할 때 고려해야 할 요소는 무엇일까요?**

A11. 

데이터의 특성(크기, 차원, 분포 형태 등), 알고리즘의 계산 복잡도 , 목적(이상치 탐지, 차원 축소 등)에 따라 적합한 군집 알고리즘을 선택해야 합니다.
데이터의 형태와 목적에 맞는 알고리즘이 성능면에서 유리합니다.